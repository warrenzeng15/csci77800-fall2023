[Companies Will Use Generative AI. But Will They Tell You About It?](https://www.wsj.com/articles/companies-will-use-generative-ai-but-will-they-tell-you-about-it-a4cab6b9)

This short article discusses a new tool that Google DeepMind has been using that helps identify whether or not an image was generated by AI. The tool is called SynthID, and essentially adds a watermark to images that were created using Imagen, (Google cloud's text-to-image) generator, which would allow other tools figure out whether or not an image was generated using AI technology. This has created a bit of discussion on whether or not there should be disclaimers for end users when they view materials, text or images, that have been created using the help of generative AI technology. As generative AI becomes more and more prevalent in our world, it makes sense for large companies to start utilizing it for marketing purposes -- designing images and slogans, creating jingles, even to help with brainstorming. The question now is: should companies disclose their use of generative AI to consumers/the general public? 

The author of this article Isabelle Bousquette, says, "Unlike manipulated images of politicians or celebrities on social media, it might not matter whether a fictional character used in an advertisement was created by a person or AI, for instance." Obviously, if generative AI is used to create something that could be extremely harmful, it is important that the public knows it is not real. This questions is thus much more focused on fictional characters (or even things that don't have characters at all). One of the possible outcomes is generative AI taking inspiration/ripping off from the work of someone else, who may even have their own work copyrighted. Would it not be appropriate for companies to disclose that they used generative AI in this case? They may even run into legal issues if their generative AI takes the of an artist that threatens to sue for damages as they were not credited.  

In the article, Bousquette also quotes the CIO of Choice Hotels, Brian Kirkland, who says, "Companies already outsource things like copywriting without disclosing who wrote the marketing material and the public doesn’t have an expectation of disclosure, he said. Similar questions came up when photo-editing platform Adobe Photoshop rose to popularity, he added, and today most companies don’t disclose that an image they are using has been photoshopped." I thought this was very interesting -- Photoshop is definitely used by tons of artists and marketers to transform or improve the quality of photos/images for advertising purposes, but companies do not bother disclosing the fact that it was used. Should generative AI be treated as sort of an advanced version of Photoshop in this sense, where it is not disclosed? 
